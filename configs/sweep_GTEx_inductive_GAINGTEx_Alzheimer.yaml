program: sweep_imputation.py
method: random
project: GTEx_imputation
metric:
  goal: minimize
  name: val_loss
parameters:
  gpu:
    value: 1
  dataset:
    value: 'GTEx'
  pathway:
    value: ''
  model:
    value: 'GAINGTEx'
  inplace_mode:
    value: False
  sweep:
    value: True
  lambd_sup:
    values: [1, 10]
  m_low:
    desc: Max probability of m
    value: 0.5
  m_high:
    desc: Min probability of m
    value: 0.5
  lr:
    desc: Learning rate for optimiser
    value: 0.001
  batch_size:
    values: [32, 64, 126]
  dropout:
    desc: Probability of dropping out a hidden unit
    values: [0, 0.1, 0.2, 0.3, 0.4, 0.5]
  bn:
    desc: Whether to use batch normalisation
    values: [True, False]
  epochs:
    desc: Maximum number of epochs to run
    value: 100
  steps_per_epoch:
    desc: Number of train steps per epoch
    value: 100
  patience:
    value: 10
  nb_layers:
    desc: Number of hidden layers
    values: [1, 2, 3, 4]
  hdim:
    desc: Hidden dimension of MLPs
    min: 100
    max: 3000
  save:
    value: False
  save_dir:
    value: '/local/scratch/rv340/gtex_imputation'